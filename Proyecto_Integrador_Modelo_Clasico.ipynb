{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11975271,"sourceType":"datasetVersion","datasetId":7530881}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PROYECTO INTEGRADOR","metadata":{}},{"cell_type":"markdown","source":"# ANÁLISIS DE SENTIMIENTOS EN RESEÑAS DE PROFESORES","metadata":{}},{"cell_type":"markdown","source":"# NOTEBOOK 2: MODELO CLÁSICO","metadata":{}},{"cell_type":"markdown","source":"Se utilizará **TF-IDF** para la vectorización y **Regresión Logística** y **Random Forest** como modelos predictivos.","metadata":{}},{"cell_type":"markdown","source":"## Preprocesamiento adicional","metadata":{}},{"cell_type":"markdown","source":"Los modelos clásicos requieren algunos pasos de preprocesamiento adicional que los modelos de deep learning no requieren. A continuación, se realizarán esos pasos para poder proceder con los modelados.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/dataset-final-definitivo/dataset_final_definitivo.csv\")\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T00:02:29.955400Z","iopub.execute_input":"2025-05-29T00:02:29.955634Z","iopub.status.idle":"2025-05-29T00:02:32.391842Z","shell.execute_reply.started":"2025-05-29T00:02:29.955617Z","shell.execute_reply":"2025-05-29T00:02:32.390847Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                     StudentComments  Sentiment\n0                                               good          1\n1                                            teacher          1\n2  friendly teacher but not enough ability to enc...          1\n3                               he is a good techer.          1\n4                                he is agood techer.          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>StudentComments</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>good</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>teacher</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>friendly teacher but not enough ability to enc...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>he is a good techer.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>he is agood techer.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"### **Eliminación de stopwords**","metadata":{}},{"cell_type":"markdown","source":"Se eliminan las **stopwords** (palabras vacías) porque son términos muy comunes como “the”, “is” o “and” que aparecen con mucha frecuencia pero aportan poca información sobre el significado del texto. Al quitarlas, se reduce el ruido y se enfoca el análisis en las palabras más relevantes para tareas como clasificación o detección de sentimientos.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\n\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\ndef remove_stopwords(text):\n    if not isinstance(text, str):\n        return \"\"\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    filtered_words = [word for word in words if word not in stop_words]\n    return ' '.join(filtered_words)\n\ndf['StudentComments'] = df['StudentComments'].astype(str).apply(remove_stopwords)\n\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T00:02:32.393575Z","iopub.execute_input":"2025-05-29T00:02:32.394054Z","iopub.status.idle":"2025-05-29T00:02:35.606223Z","shell.execute_reply.started":"2025-05-29T00:02:32.394030Z","shell.execute_reply":"2025-05-29T00:02:35.605020Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"                                     StudentComments  Sentiment\n0                                               good          1\n1                                            teacher          1\n2  friendly teacher enough ability encourage student          1\n3                                        good techer          1\n4                                       agood techer          1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Vectorización TF-IDF y Regresión Logística","metadata":{}},{"cell_type":"markdown","source":"La vectorización que se utilizará para los modelos clásicos será la **TF-IDF**.\n\nEl dataset se dividió en un conjunto de **training** y un conjunto de **test**. \n\nEl primer modelo que se utilizará para realizar el análisis de sentimientos será la **regresión logística**. ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n\ntfidf = TfidfVectorizer(max_features=5000)\nX = tfidf.fit_transform(df['StudentComments'])\n\ny = df['Sentiment'].astype(int) \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(max_iter=1000, multi_class='ovr')\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T00:02:35.607161Z","iopub.execute_input":"2025-05-29T00:02:35.607552Z","iopub.status.idle":"2025-05-29T00:02:44.524799Z","shell.execute_reply.started":"2025-05-29T00:02:35.607529Z","shell.execute_reply":"2025-05-29T00:02:44.523256Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8560911274130261\n              precision    recall  f1-score   support\n\n           0       0.71      0.42      0.52     14514\n           1       0.87      0.96      0.92     61687\n\n    accuracy                           0.86     76201\n   macro avg       0.79      0.69      0.72     76201\nweighted avg       0.84      0.86      0.84     76201\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"El modelo **Regresión Logística** alcanzó una accuracy del 85.6 %, lo cual indica que clasifica correctamente la polaridad de los comentarios en aproximadamente el 86 % de los casos. Aunque esta cifra refleja un buen rendimiento general, es fundamental considerar el **F1-score** para evaluar con mayor precisión el comportamiento del modelo en cada clase.\n\nEl F1-score para la clase negativa (0) es **0.52**, significativamente menor que el de la clase positiva (1), que alcanza 0.92. Esto evidencia un **rendimiento desequilibrado**, donde el modelo funciona mucho mejor para identificar comentarios positivos que negativos.\n\nEn la clase negativa, la precisión es de 0.71, lo que indica que, cuando el modelo predice que un comentario es negativo, generalmente acierta. Sin embargo, el recall es de apenas 0.42, lo que sugiere que muchos comentarios negativos no están siendo detectados. Por el contrario, en la clase positiva, el modelo muestra un recall muy alto (0.96) y una precisión también elevada (0.87), lo que significa que identifica correctamente la gran mayoría de los comentarios positivos, con pocos errores.","metadata":{}},{"cell_type":"markdown","source":"## Vectorización TF-IDF y Random Forest","metadata":{}},{"cell_type":"markdown","source":"El segundo modelo que se utilizará para realizar el análisis de sentimientos será **random forest**.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n\ntfidf = TfidfVectorizer(max_features=5000)\nX = tfidf.fit_transform(df['StudentComments'])\n\ny = df['Sentiment'].astype(int)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T00:02:44.577641Z","iopub.execute_input":"2025-05-29T00:02:44.577903Z","iopub.status.idle":"2025-05-29T00:21:26.357811Z","shell.execute_reply.started":"2025-05-29T00:02:44.577877Z","shell.execute_reply":"2025-05-29T00:21:26.356281Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8245823545622761\n              precision    recall  f1-score   support\n\n           0       0.54      0.53      0.53     14514\n           1       0.89      0.89      0.89     61687\n\n    accuracy                           0.82     76201\n   macro avg       0.71      0.71      0.71     76201\nweighted avg       0.82      0.82      0.82     76201\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"El modelo de **Random Forest** alcanzó una accuracy del 82.5 %, lo que indica que clasifica correctamente aproximadamente el 82 % de los comentarios como positivos o negativos. Aunque esta métrica sugiere un buen rendimiento global, es importante analizar el **F1-score** por clase para comprender mejor el comportamiento del modelo, especialmente en datasets desbalanceados.\n\nEl F1-score para la clase negativa (0) es de **0.53**, mientras que para la clase positiva (1) es de 0.89, lo que evidencia una brecha significativa en el desempeño del modelo entre ambas clases. En otras palabras, el modelo es mucho más efectivo al identificar comentarios positivos que negativos.\n\nEn la clase negativa, tanto la precisión como el recall están en torno a 0.53, lo que indica un rendimiento limitado: el modelo acierta poco más de la mitad de las veces tanto al predecir comentarios negativos como al detectarlos. En contraste, para los comentarios positivos, el modelo logra una precisión y un recall altos (0.89 en ambos casos), lo que muestra una capacidad sólida para identificar correctamente la mayoría de los comentarios positivos.","metadata":{}},{"cell_type":"markdown","source":"## Cross-validation","metadata":{}},{"cell_type":"markdown","source":"Dado que el modelo de **Random Forest** obtuvo un mejor F1-Score que la Regresión Logística en la categoría negativa, que es la métrica en la que nos guiamos puesto que es la clase minoritaria, se selecciona como el mejor modelo clásico para continuar el proyecto.\n\nPara asegurar una evaluación robusta, se aplicará el método de **cross-validation**, una técnica estadística que permite validar la estabilidad y generalización del modelo al entrenarlo y evaluarlo en diferentes subconjuntos de los datos. En este caso, se empleará la estrategia de **K-folds** con **5 pliegues**, lo que implica dividir el conjunto de datos en cinco partes y rotar la validación en cada una.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline\nimport numpy as np\n\ntfidf = TfidfVectorizer(max_features=5000)\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n\npipeline = make_pipeline(tfidf, model)\n\nX = df['StudentComments']\ny = df['Sentiment'].astype(int)\n\nscores = cross_val_score(pipeline, X, y, cv=5, scoring='f1_macro')\n\nprint(\"F1-score (macro) por fold:\", scores)\nprint(\"F1-score (macro) promedio:\", np.mean(scores))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T00:21:26.358577Z","iopub.execute_input":"2025-05-29T00:21:26.358825Z","iopub.status.idle":"2025-05-29T01:51:50.439448Z","shell.execute_reply.started":"2025-05-29T00:21:26.358802Z","shell.execute_reply":"2025-05-29T01:51:50.438703Z"}},"outputs":[{"name":"stdout","text":"F1-score (macro) por fold: [0.65456388 0.69775576 0.71876023 0.73141012 0.73763092]\nF1-score (macro) promedio: 0.7080241828868828\n","output_type":"stream"}],"execution_count":6}]}